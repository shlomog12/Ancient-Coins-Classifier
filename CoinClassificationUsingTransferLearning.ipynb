{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJmySi1uhrjd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import PIL\n",
        "import pytz\n",
        "import time,copy\n",
        "import numpy as np\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms.transforms import ToTensor\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torchvision import models\n",
        "from torch.optim import lr_scheduler as schedulers\n",
        "import tqdm.notebook as tq\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK8u5NCI9BcP"
      },
      "source": [
        "## Data Class and Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vFlC3R2hwOt"
      },
      "outputs": [],
      "source": [
        "class CoinImageDataset(Dataset):\n",
        "  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_dir = img_dir\n",
        "    self.img_lables = pd.read_csv(annotations_file)\n",
        "    self.transform = transform\n",
        "    self.traget_transform = target_transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.img_lables)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_lables.iloc[idx, 0])\n",
        "    \n",
        "    image = cv.imread(img_path+\".jpg\")\n",
        "    \n",
        "    label = self.img_lables.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    sample = {\"image\": image, \"label\": label}\n",
        "\n",
        "\n",
        "    return sample\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UDvZzZiChxp9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsHunrphh_Pt"
      },
      "outputs": [],
      "source": [
        "training_data = \"/content/drive/MyDrive/Coin-classification-project/resized_train\"\n",
        "training_annotations = \"/content/drive/MyDrive/Coin-classification-project/annotation_files/train_annotations_3classes.csv\"\n",
        "\n",
        "test_data = \"/content/drive/MyDrive/Coin-classification-project/resized_test\"\n",
        "test_annotations = \"/content/drive/MyDrive/Coin-classification-project/annotation_files/test_annotations_3classes.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OzHN_xr9KuQ"
      },
      "source": [
        "# Initialize DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pkg4CCMvighm"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_train = CoinImageDataset(annotations_file=training_annotations, img_dir=training_data, transform=ToTensor())\n",
        "dataloader_train = DataLoader(dataset_train, batch_size = 32, shuffle=True)\n",
        "\n",
        "dataset_test = CoinImageDataset(annotations_file=test_annotations, img_dir=test_data, transform=ToTensor())\n",
        "dataloader_test = DataLoader(dataset_test, batch_size = 32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVlcdZKK6JFr"
      },
      "source": [
        "View a Sample from the Data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rK055jFI6OC_"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(dataloader_train))\n",
        "img = batch[\"image\"][0]\n",
        "label = batch[\"label\"][0]\n",
        "plt.imshow(img.permute(2,1,0))\n",
        "print(label.numpy)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation with Rotation Technique\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lGPT9KeICpSR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kbd3MGjzCI75"
      },
      "outputs": [],
      "source": [
        "def get_image_rotations(img):\n",
        "  degs = [10,20,30,40,50]\n",
        "  rotated_imgs = [transforms.RandomRotation(degrees=deg)(img) for deg in degs]\n",
        "  return rotated_imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UqeIAWb3CNCn"
      },
      "outputs": [],
      "source": [
        "def augment_batch(inputs,labels):\n",
        "  batch_size = len(inputs)\n",
        "  labels_lst = labels.tolist()    \n",
        "  for i in range(batch_size):\n",
        "    img = inputs[i]\n",
        "    label = labels_lst[i]\n",
        "    rotated_imgs = get_image_rotations(img)\n",
        "    stack_of_rotated_imgs = torch.stack(rotated_imgs)\n",
        "    inputs = torch.cat((inputs, stack_of_rotated_imgs), 0)\n",
        "    for j in rotated_imgs:\n",
        "      labels_lst.append(label)\n",
        "      \n",
        "  labels = torch.Tensor(labels_lst).type(torch.LongTensor)\n",
        "  return inputs, labels "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74V09l0O9gEY"
      },
      "source": [
        "# Define Model and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HELiOtG8_T9"
      },
      "outputs": [],
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpSdWO0A61QN"
      },
      "outputs": [],
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=False)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jLaN_bLk9oXI"
      },
      "outputs": [],
      "source": [
        "num_classes = 3\n",
        "epochs = 100\n",
        "feature_extract = False\n",
        "TRAINING_RESULTS_PATH = '/content/drive/MyDrive/Coin-classification-project/results/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YjAMVEHCwOD"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_ft, input_size = initialize_model('resnet', 3, True,True)\n",
        "model_ft = model_ft.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Model"
      ],
      "metadata": {
        "id": "8ptr9FurDhPL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rTn32cMJby5K"
      },
      "outputs": [],
      "source": [
        "from numpy.ma.core import size\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "\n",
        "  timezone = pytz.timezone(\"Israel\")\n",
        "  now_time = datetime.now(timezone).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "  dir_of_res_path = TRAINING_RESULTS_PATH + now_time   # same to loger\n",
        "  if not os.path.isdir(dir_of_res_path):\n",
        "    os.makedirs(dir_of_res_path)\n",
        "\n",
        "  since = time.time()\n",
        "  val_acc_history = []\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "\n",
        "  results_df = pd.DataFrame([], columns=['train_loss', 'val_loss'])\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in tq.tqdm(range(num_epochs)):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    train_loss, val_loss = 0, 0\n",
        "    train_acc, val_acc = 0, 0\n",
        "\n",
        "    x_len = 0\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "      \n",
        "      for batch in tq.tqdm(dataloaders[phase]):\n",
        "        inputs = batch['image']\n",
        "        labels = batch['label']\n",
        "        \n",
        "        if phase == 'train':\n",
        "            inputs, labels = augment_batch(inputs,labels)\n",
        "            x_len += labels.size(0)\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = nn.Softmax(dim=1)(model(inputs))\n",
        "          loss = criterion(outputs, labels)\n",
        "          \n",
        "          _, preds = torch.max(outputs, 1)\n",
        "\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            train_acc += torch.sum(preds == labels.data)\n",
        "          \n",
        "          if phase == 'val':\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_acc += torch.sum(preds == labels.data)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    num_rotations = 6\n",
        "    len_train = len(dataloaders['train'].dataset) * num_rotations\n",
        "    epoch_train_loss = train_loss / len_train\n",
        "    epoch_train_acc = train_acc.double() / len_train    \n",
        "    epoch_val_loss = val_loss / len(dataloaders['val'].dataset)\n",
        "    epoch_val_acc = val_acc.double() / len(dataloaders['val'].dataset)\n",
        "    if phase == 'train':\n",
        "      epoch_loss = running_loss / len_train\n",
        "      epoch_acc = running_corrects.double() / len_train\n",
        "\n",
        "    else:\n",
        "      epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "      epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "    with open(dir_of_res_path+'/res.txt', 'a',) as f:\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f}'.format('train', epoch_train_loss, epoch_train_acc),file=f)\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f}'.format('val', epoch_val_loss, epoch_val_acc),file=f)\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format('train', epoch_train_loss, epoch_train_acc))\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format('val', epoch_val_loss, epoch_val_acc))\n",
        "    if phase == 'val' and epoch_acc > best_acc:\n",
        "      best_acc = epoch_acc\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    if phase == 'val':\n",
        "      val_acc_history.append(epoch_acc)\n",
        "      \n",
        "    epoch_val_loss = np.round(epoch_val_loss, 4)\n",
        "    epoch_train_loss = np.round(epoch_train_loss, 4)\n",
        "    results_df.loc[len(results_df)] = [epoch_train_loss, epoch_val_loss]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  with open(dir_of_res_path+'/res.txt', 'a',) as f:\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60),file=f)\n",
        "    print('Best val Acc: {:4f}'.format(best_acc),file=f)\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  torch.save(model.state_dict(), dir_of_res_path + f'/model_ft_{best_acc}.pth')\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.plot(results_df['train_loss'], color='gold', label='train')\n",
        "  plt.plot(results_df['val_loss'], color='purple', label='val')\n",
        "  plt.ylabel('Loss', fontsize=25)\n",
        "  plt.xlabel('Epoch', fontsize=25)\n",
        "  plt.legend()\n",
        "  plt.savefig(dir_of_res_path + '/final_loss_plot.jpeg')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return model, val_acc_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9_KIXywNydf0"
      },
      "outputs": [],
      "source": [
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "    print(\"end\")\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "49XPuHa4DeS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sEtgFoM1Xzhf"
      },
      "outputs": [],
      "source": [
        "optimizer_ft = optim.SGD(params_to_update, lr=0.01, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "dataloaders_dict = {'train': dataloader_train, 'val': dataloader_test}\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=epochs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CoinClassificationUsingTransferLearning.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}